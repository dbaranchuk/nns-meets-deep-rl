{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity graph construction on DEEP1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import os.path as osp\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "sys.path.append('..')\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "import lib\n",
    "\n",
    "print(\"Numpy: {}, Torch: {}\".format(np.__version__, torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download vertices, graph edges and ground truth neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/DEEP1M'\n",
    "\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    assert not DATA_DIR.endswith(os.sep), 'please do not put \"/\" at the end of DATA_DIR'\n",
    "    !mkdir -p {DATA_DIR}\n",
    "    !curl -L  https://www.dropbox.com/sh/l2981vqyo6qejom/AABm-XWCELQ4Akzt6u0c7jdNa?dl=q > {DATA_DIR}/deep_1m.zip\n",
    "    !cd {DATA_DIR} && unzip deep_1m.zip && rm deep_1m.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "NOTE: this config requires ~10.5GB GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = random.randint(0, 2**32-1)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.random.manual_seed(seed)\n",
    "print(\"Random seed: %d\" % seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Graph params #\n",
    "################\n",
    "\n",
    "graph_type = 'nsw'        # 'hnsw', 'nsw' or 'nsg'\n",
    "M = 14                   # degree parameter for NSW (Max degree is 2*M)\n",
    "ef = 12                   # search algorithm parameter, sets the operating point\n",
    "R = 16                    #  degree parameter for NSG (corresponds to max degree)\n",
    "k = 1                     # Number of answers per query. Need for Recall@k\n",
    "\n",
    "assert k <= ef\n",
    "\n",
    "nn = 200                  # Number of NN in initial KNNG that is used for NSG construction \n",
    "efC = 500                 # efConstruction used for NSW graph\n",
    "ngt = 1                   # Number of ground truth answers per query\n",
    "val_queries_size = 20000  # Number of queries for validation\n",
    "\n",
    "#################\n",
    "# Reward params #\n",
    "#################\n",
    "\n",
    "max_dcs = 1500           # reward hyperparameter\n",
    "\n",
    "################\n",
    "# Agent params #\n",
    "################\n",
    "\n",
    "hidden_size = 2048        # number of hidden units\n",
    "\n",
    "####################\n",
    "# Algorithm params #\n",
    "####################\n",
    "\n",
    "samples_in_batch = 70000  # Reduce for larger hidden_size to fit in GPU memory \n",
    "Fvp_speedup = 5           # fraction of samples for Fisher vector product estimation \n",
    "                          # Reflects on the iteration time (<10 is okay)\n",
    "                          # It significantly affects training time\n",
    "                          \n",
    "Fvp_min_batches = 10      # Min number of batches used for Fvp computation \n",
    "                          # (min number of samples = Fvp_min_batches*samples_in_batch) \n",
    "                          # Can be not met when total number of samples < Fvp_min_batches*samples_in_batch\n",
    "                          \n",
    "edge_patience = 50        # How many iterations are needed without the change of edge probability \n",
    "                          # to denote the prediction as confident and make it deterministic\n",
    "                          # Very important for training procedure efficiency\n",
    "\n",
    "Fvp_type = 'fim'          # Fisher vector product implementation: ['forward', 'fim']\n",
    "entropy_reg = 0.01        # coefficient in front of the entropy regularizer term \n",
    "batch_size = 100000       # number of sessions per batch\n",
    "\n",
    "n_jobs = 8                # Number of threads for C++ sampling\n",
    "max_steps = 800           # Max number of training iterations\n",
    "\n",
    "# Recover settings\n",
    "restore_step = None      # the iteration step from which you want to recover the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib\n",
    "import os.path as osp\n",
    "\n",
    "graph_params = { \n",
    "    'vertices_path': osp.join(DATA_DIR, 'deep_base.fvecs'),\n",
    "\n",
    "    'train_queries_path': osp.join(DATA_DIR, 'deep_learn_filtered.fvecs'),\n",
    "    'test_queries_path': osp.join(DATA_DIR, 'deep_query.fvecs'),\n",
    "    \n",
    "    'train_gt_path': osp.join(DATA_DIR, 'train_gt.ivecs'),\n",
    "    'test_gt_path': osp.join(DATA_DIR, 'test_gt.ivecs'),\n",
    "#     ^-- comment these 2 lines to re-compute ground truth ids (if you don't have pre-computed ground truths)\n",
    "    \n",
    "    'val_queries_size': val_queries_size,\n",
    "    'ground_truth_n_neighbors': ngt,  # for each query, finds this many nearest neighbors via brute force\n",
    "    'graph_type': graph_type\n",
    "}\n",
    "\n",
    "\n",
    "if graph_type == 'nsg':\n",
    "    graph_params['edges_path'] = osp.join(DATA_DIR, 'deep_R{R}_200nn.nsg'.format(R=R))\n",
    "elif graph_type == 'nsw':\n",
    "    graph_params['edges_path'] = osp.join(DATA_DIR, 'deep1m_M{M}_ef{efC}_onelevel1.ivecs'.format(M=M, efC=efC))\n",
    "    graph_params['initial_vertex_id'] = 0 # by default, starts search from this vertex\n",
    "else:\n",
    "    raise ValueError(\"Wrong graph type: ['nsg', 'nsw']\")\n",
    "    \n",
    "graph = lib.Graph(**graph_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if graph_type == 'nsw' or graph_type == 'hnsw':\n",
    "    exp_name = '{data_name}_{graph_type}_k{k}_M{M}_ef{ef}_max-dcs{max_dcs}_hid-size{hidden_size}_entropy{entropy_reg}_patience{edge_patience}_seed_{seed}'.format(\n",
    "        data_name=osp.split(DATA_DIR)[-1], k=k, M=M, ef=ef, hidden_size=hidden_size,\n",
    "        max_dcs=max_dcs, entropy_reg=entropy_reg, graph_type=graph_type, edge_patience=edge_patience, seed=seed,\n",
    "    )\n",
    "elif graph_type == 'nsg':\n",
    "    exp_name = '{data_name}_{graph_type}_k{k}_R{R}_ef{ef}_max-dcs{max_dcs}_hid-size{hidden_size}_entropy{entropy_reg}_patience{edge_patience}_seed_{seed}'.format(\n",
    "        data_name=osp.split(DATA_DIR)[-1], k=k, R=R, ef=ef, hidden_size=hidden_size, \n",
    "        max_dcs=max_dcs, entropy_reg=entropy_reg, graph_type=graph_type, edge_patience=edge_patience, seed=seed\n",
    "    )\n",
    "    \n",
    "print('exp name:', exp_name)\n",
    "# !rm {'./runs/' + exp_name} -rf # KEEP COMMENTED!\n",
    "assert (restore_step is not None) or not os.path.exists('./runs/' + exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HNSW, Agent, Reward, Baseline and Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnsw = lib.ParallelHNSW(graph, ef=ef, k=k, edge_patience=edge_patience, n_jobs=n_jobs)\n",
    "\n",
    "if restore_step is not None:\n",
    "    agent = torch.load(\"runs/{}/agent.{}.pth\".format(exp_name, restore_step))\n",
    "    baseline = torch.load(\"runs/{}/baseline.{}.pth\".format(exp_name, restore_step))\n",
    "    hnsw.edge_confidence = torch.load(\"runs/{}/edge_confidence.{}.pth\".format(exp_name, restore_step))\n",
    "else:\n",
    "    agent = lib.SimpleNeuralAgent(graph.vertices.shape[1], hidden_size=hidden_size)\n",
    "    baseline = lib.SessionBaseline(graph.train_queries.size(0))\n",
    "    \n",
    "reward = lib.MaxDCSReward(k=k, max_dcs=max_dcs)\n",
    "trainer = lib.EfficientTRPO(agent, hnsw, reward, baseline,\n",
    "                            samples_in_batch=samples_in_batch,\n",
    "                            Fvp_type=Fvp_type,\n",
    "                            Fvp_speedup=Fvp_speedup,\n",
    "                            Fvp_min_batches=Fvp_min_batches,\n",
    "                            entropy_reg=entropy_reg,\n",
    "                            writer=SummaryWriter('./runs/' + exp_name))\n",
    "\n",
    "if restore_step is not None:\n",
    "    trainer.step = restore_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "moving_average = lambda x, **kw: DataFrame({'x':np.asarray(x)}).x.ewm(**kw).mean().values\n",
    "reward_history = []\n",
    "best_val_step = 0\n",
    "best_val_reward = 0\n",
    "\n",
    "# generate batches of [queries, ground truth, train_query_ids (for baseline)]\n",
    "train_query_ids = torch.arange(graph.train_queries.size(0))\n",
    "train_batcher = lib.utils.iterate_minibatches(graph.train_queries, graph.train_gt, train_query_ids, \n",
    "                                              batch_size=batch_size)\n",
    "\n",
    "# generate batches of [queries, ground truth]           \n",
    "val_iterator = lib.utils.iterate_minibatches(graph.val_queries, graph.val_gt, \n",
    "                                             batch_size=graph.val_queries.size(0))\n",
    "\n",
    "dev_iterator = lib.utils.iterate_minibatches(graph.test_queries, graph.test_gt, \n",
    "                                             batch_size=graph.test_queries.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch_queries, batch_gt, batch_query_ids in train_batcher:\n",
    "    start = time.time()\n",
    "    torch.cuda.empty_cache()\n",
    "    mean_reward = trainer.train_step(batch_queries, batch_gt, query_index=batch_query_ids)\n",
    "    reward_history.append(mean_reward)\n",
    "        \n",
    "    if trainer.step % 25 == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "        val_reward = trainer.evaluate(*next(val_iterator), prefix='val')\n",
    "        if val_reward > best_val_reward and \\\n",
    "           trainer.step % 50 == 0 and \\\n",
    "           trainer.step > max_steps // 2:\n",
    "            best_val_reward = val_reward\n",
    "            best_val_step = trainer.step\n",
    "        \n",
    "    if trainer.step % 50 == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "        _ = trainer.evaluate(*next(dev_iterator))\n",
    "        print(end=\"Saving...\")\n",
    "        torch.save(agent, \"runs/{}/agent.{}.pth\".format(exp_name, trainer.step))\n",
    "        torch.save(baseline, \"runs/{}/baseline.{}.pth\".format(exp_name, trainer.step))\n",
    "        torch.save(hnsw.edge_confidence, \"runs/{}/edge_confidence.{}.pth\".format(exp_name, trainer.step))\n",
    "        print('Done!')\n",
    "    \n",
    "    if trainer.step % 1 == 0:\n",
    "        clear_output(True)\n",
    "        plt.title('train reward over time')\n",
    "        plt.plot(moving_average(reward_history, span=50))\n",
    "        plt.scatter(range(len(reward_history)), reward_history, alpha=0.1)\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        print(\"step=%i, mean_reward=%.3f, time=%.3f\" % \n",
    "              (trainer.step, np.mean(reward_history[-100:]), time.time()-start))\n",
    "    \n",
    "    if trainer.step >= max_steps: break\n",
    "\n",
    "#protip: run tensorboard in ./runs to get all metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best step on validation: %d\" % best_val_step)\n",
    "agent = torch.load(\"runs/{}/agent.{}.pth\".format(exp_name, best_val_step))\n",
    "hnsw.edge_confidence = torch.load(\"runs/{}/edge_confidence.{}.pth\".format(exp_name, best_val_step))\n",
    "trainer.step = best_val_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "agent.cuda()\n",
    "torch.cuda.empty_cache()\n",
    "state = agent.prepare_state(graph, device='cuda')\n",
    "\n",
    "new_edges = defaultdict(list)\n",
    "\n",
    "for i in range(len(hnsw.from_vertex_ids)):\n",
    "    from_vertex_ids = np.array(hnsw.from_vertex_ids[i])\n",
    "    to_vertex_ids = np.array(hnsw.to_vertex_ids[i])\n",
    "    edge_confidence = np.array(hnsw.edge_confidence[i])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        edges_logp = agent.get_edge_logp(from_vertex_ids, to_vertex_ids,\n",
    "                                        state=state, device='cuda').cpu()\n",
    "        edges_mask = edges_logp.argmax(-1).numpy() == 1\n",
    "        edges_mask = edges_mask | (edge_confidence == hnsw.edge_patience)\n",
    "        edges_mask = edges_mask & (edge_confidence != -hnsw.edge_patience)\n",
    "    from_vertex_ids = from_vertex_ids[edges_mask]\n",
    "    to_vertex_ids = to_vertex_ids[edges_mask]\n",
    "    \n",
    "    for from_vertex_id, to_vertex_id in zip(from_vertex_ids, to_vertex_ids):\n",
    "        new_edges[from_vertex_id].append(to_vertex_id)\n",
    "    for i in range(len(graph.edges)):\n",
    "        if len(new_edges[i]) == 0:\n",
    "            new_edges[i] = []\n",
    "\n",
    "#Save constructed graph\n",
    "new_edges=dict(sorted(new_edges.items())) # to preserve edges in the correct order in the file\n",
    "lib.write_edges(\"runs/{}/graph.{}.ivecs\".format(exp_name, trainer.step), new_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate constructed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnsw.max_trajectory = 500  # Set larger number of hops allowed to the search algorithm \n",
    "                          # to deal with large heap_sizes\n",
    "\n",
    "for heap_size in range(12, 121, 4):\n",
    "    algo_hnsw = lib.BaseAlgorithm(\n",
    "        agent=agent, hnsw=hnsw,\n",
    "        reward=lambda actions, **kw: [0] * len(actions),\n",
    "        writer=trainer.writer, device='cuda',\n",
    "    )\n",
    "    algo_hnsw.hnsw.ef = heap_size\n",
    "    algo_hnsw.step = trainer.step  # for tensorboard\n",
    "\n",
    "    metrics = algo_hnsw.get_session_batch(graph.test_queries, graph.test_gt, greedy=True,\n",
    "                             summarize=True, write_logs=False, prefix='dev', is_evaluate=True)['summary']\n",
    "    sys.stderr.flush()\n",
    "    print(\"Ef %i | Recall@%d %.4f | Distances: %.1f\" % \n",
    "          (heap_size, k, metrics['dev/recall@%d' % k], metrics['dev/distance_computations']),\n",
    "          flush=True,\n",
    "         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
